{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comet Test Notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (3.1.11) detected. current: 3.1.12 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/lizette95/team-rm5-sigmoidfreuds/8982e217023d48a7bcef986270a9e081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "experiment = Experiment(api_key=\"zNkJjcVKOMD5gKd05z6CwT4OD\",\n",
    "                        project_name=\"team-rm5-sigmoidfreuds\", workspace=\"lizette95\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "# Install Prerequisites\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install wordcloud comet_ml scikit-learn scikit-plot\n",
    "# nltk.download('vader_lexicon')\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Preprocessing\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Modelling\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Performance Evaluation\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikitplot.metrics import plot_roc, plot_confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score\n",
    "\n",
    "# Display\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=1)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df['token'] = df['message'].apply(TweetTokenizer().tokenize) ## first we tokenize\n",
    "    df['punc'] = df['token'].apply(lambda x : [i for i in x if i not in list(string.punctuation)]) ## remove punctuations\n",
    "    df['dig'] = df['punc'].apply(lambda x: [i for i in x if i not in list(string.digits)]) ## remove digits\n",
    "    df['final'] = df['dig'].apply(lambda x: [i for i in x if len(i) > 1]) ## remove all words with only 1 character\n",
    "    return df['final']\n",
    "\n",
    "train_data['final'] = clean(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_of_speech(word):\n",
    "    probable_part_of_speech = wordnet.synsets(word) ## finding word that is most similar (synonyms) for semantic reasoning\n",
    "    pos_counts = Counter() # instantiating our counter class\n",
    "    \n",
    "    ## finding part of speech of word if part of speech is either noun, verb, adjective etc and add it up in a list\n",
    "    pos_counts[\"n\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"n\"]  )\n",
    "    pos_counts[\"v\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"v\"]  )\n",
    "    pos_counts[\"a\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"a\"]  )\n",
    "    pos_counts[\"r\"] = len(  [ item for item in probable_part_of_speech if item.pos()==\"r\"]  )\n",
    "    most_likely_part_of_speech = pos_counts.most_common(1)[0][0] ## will extract the most likely part of speech from the list\n",
    "    return most_likely_part_of_speech\n",
    "\n",
    "normalizer = WordNetLemmatizer()\n",
    "def lemmatise_words(df):\n",
    "    df['lemma'] = df['final'].apply(lambda x: [normalizer.lemmatize(token, get_part_of_speech(token)) for token in x]) ## lemmatize by way of applying part of speech\n",
    "    return df['lemma']\n",
    "\n",
    "train_data['lemma'] = lemmatise_words(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data['lemma']\n",
    "y = train_data['sentiment']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(X_train.apply(' '.join))\n",
    "X_val = list(X_val.apply(' '.join))\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, smooth_idf = True, max_df = 0.3, min_df = 5, token_pattern = r'\\w{1,}', strip_accents = 'ascii', ngram_range = (1, 5))\n",
    "vectorizer.fit(X_train)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_val = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "# logreg.fit(X_train, y_train)\n",
    "# y_pred = logreg.predict(X_val)\n",
    "# print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nResults\\nConfusion matrix \\n {}\".format(confusion_matrix(y_val, y_pred)))\n",
    "# f1 = f1_score(y_val, y_pred,average=\"macro\")\n",
    "# precision = precision_score(y_val, y_pred,average=\"macro\")\n",
    "# recall = recall_score(y_val, y_pred,average=\"macro\")\n",
    "# param_grid = {'penalty': ['l1','l2'], 'C': [1,100,1e5],'multi_class' : ['auto', 'ovr', 'multinomial']}\n",
    "# params = {\"random_state\": 42,\n",
    "#           \"model_type\": \"logreg\",\n",
    "#           \"scaler\": \"standard scaler\",\n",
    "#           \"param_grid\": \"str(param_grid)\",\n",
    "#           \"stratify\": True,\n",
    "#           }\n",
    "# metrics = {\"f1\": f1,\n",
    "#            \"recall\": recall,\n",
    "#            \"precision\": precision\n",
    "#            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment.log_parameters(params)\n",
    "# experiment.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.55      0.59       126\n",
      "           0       0.50      0.51      0.50       224\n",
      "           1       0.81      0.83      0.82       895\n",
      "           2       0.78      0.76      0.77       337\n",
      "\n",
      "    accuracy                           0.75      1582\n",
      "   macro avg       0.68      0.66      0.67      1582\n",
      "weighted avg       0.75      0.75      0.75      1582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linsvc = LinearSVC()\n",
    "linsvc .fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results\n",
      "Confusion matrix \n",
      " [[ 69  23  31   3]\n",
      " [ 14 115  78  17]\n",
      " [ 21  77 745  52]\n",
      " [  2  17  63 255]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nResults\\nConfusion matrix \\n {}\".format(confusion_matrix(y_val, y_pred)))\n",
    "f1 = f1_score(y_val, y_pred,average=\"macro\")\n",
    "precision = precision_score(y_val, y_pred,average=\"macro\")\n",
    "recall = recall_score(y_val, y_pred,average=\"macro\")\n",
    "param_grid = {'penalty': ['l1','l2'], 'C': [0.1,1,10,100,1000],'multi_class' : ['crammer_singer', 'ovr']}\n",
    "params = {\"random_state\": 42,\n",
    "          \"model_type\": \"linsvc\",\n",
    "          \"scaler\": \"standard scaler\",\n",
    "          \"param_grid\": \"str(param_grid)\",\n",
    "          \"stratify\": True,\n",
    "          }\n",
    "metrics = {\"f1\": f1,\n",
    "           \"recall\": recall,\n",
    "           \"precision\": precision\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.log_parameters(params)\n",
    "experiment.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/lizette95/team-rm5-sigmoidfreuds/8982e217023d48a7bcef986270a9e081\n",
      "COMET INFO:   Metrics:\n",
      "COMET INFO:     f1        : 0.6723954115038295\n",
      "COMET INFO:     precision : 0.6847203520316227\n",
      "COMET INFO:     recall    : 0.6625226743155694\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     model_type   : linsvc\n",
      "COMET INFO:     param_grid   : str(param_grid)\n",
      "COMET INFO:     random_state : 42\n",
      "COMET INFO:     scaler       : standard scaler\n",
      "COMET INFO:     stratify     : True\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     code                : 1 (26 KB)\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: Still uploading\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"https://www.comet.ml/lizette95/team-rm5-sigmoidfreuds/8982e217023d48a7bcef986270a9e081\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x248e483d9c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
